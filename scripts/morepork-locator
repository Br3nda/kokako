#!/usr/bin/python
import argparse
import os
import sys

from kokako.score import get_audio

import numpy as np
from matplotlib import mlab, pyplot as plt

from scipy.signal import fftconvolve

DO_PRETTY_PICTURES = False

if DO_PRETTY_PICTURES:
    from matplotlib import pylab
    specgram = pylab.specgram
    maybe_show = pylab.show
else:
    specgram = mlab.specgram
    def maybe_show():
        pass


NFFT = 512
LOWER_CALL_FREQUENCY = 740
UPPER_CALL_FREQUENCY = 1050
TARGET_LENGTH = 0.72
TARGET_GAP = 0.24
TARGET_LEFT = 0.28
TARGET_RIGHT = 0.20
THRESHOLD = 1.8
STOP_TRYING_THRESHOLD = 50
CALL_RATIO_THRESHOLD_LEFT = 1.6
CALL_RATIO_THRESHOLD_RIGHT = 1.2
CALL_DIFF_THRESHOLD_LEFT = 2.9
CALL_DIFF_THRESHOLD_RIGHT = 0.5

USE_CALL_RATIO = False

MAX_CALL_LENGTH = 1.5 #seconds


def median5(m):
    s = [m[0]]
    e = [m[-1]]
    return np.median([np.concatenate((s * 2, m[:-2])),
                      np.concatenate((s, m[:-1])),
                      m,
                      np.concatenate((m[1:], e)),
                      np.concatenate((m[2:], e * 2))
                  ], 0)

def smooth(m, radius=3, shape=5):
    w = np.kaiser(radius * 2 + 1, shape)
    m = np.pad(m[:], radius, 'mean', stat_length=radius*2)
    return np.convolve(w / w.sum(), m, 'valid')


def find_calls_in_call_diff(call_diff, threshold_left, threshold_right, samples2secs):
    possible_starts = np.where(call_diff > threshold_left)[0]

    #coalesce possibles into actual syllables
    starts = []
    prev = None
    start = None
    for p in possible_starts:
        if p - 1 != prev: # a discontinuity
            if prev is not None and start is not None:
                starts.append((start, prev + 1))
            start = p
        prev = p
    if prev is not None:
        starts.append((start, prev - 1))

    #print samples2secs
    timed_starts = [(x * samples2secs, y * samples2secs) for x, y in starts]

    print timed_starts

    candidates = []
    for l_start, l_stop in starts:
        #leave a little gap to let first syllable drop below last syllable threshold
        in_call = False
        r_start = r_stop = None
        for k in range(l_stop + 3, min(len(call_diff), l_stop + int(MAX_CALL_LENGTH / samples2secs))):
            if call_diff[k] > threshold_right:
                if not in_call:
                    r_start = k
                in_call = True
            elif in_call:
                r_stop = k
                break

        if r_stop is not None:
            left_strength = np.median(call_diff[l_start:l_stop])
            right_strength = np.median(call_diff[r_start:r_stop])
            #print l_start, l_stop, left_strength, right_strength
            left_start = l_start * samples2secs
            left_stop = l_stop * samples2secs
            right_start = r_start * samples2secs
            right_stop = r_stop * samples2secs
            overall_err = (right_stop - left_start - TARGET_LENGTH) ** 2
            left_err = (left_stop - left_start  - TARGET_LEFT) ** 2
            gap_err = (right_start - left_stop - TARGET_GAP) ** 2
            right_err = (right_stop - right_start - TARGET_RIGHT) ** 2
            left_weakness = 1.0 / (left_strength + 1e-3) ** 2
            right_weakness = 0.4 / (right_strength + 1e-3) ** 2
            err = (overall_err * 6 + left_err + gap_err * 2 + right_err + left_weakness + right_weakness)
            print ("%.2f-%.2f: err %s overall %s left %s right %s gap %s weakness: l %s r %s" %
                   (left_start, right_stop, err, overall_err, left_err, right_err, gap_err, left_weakness, right_weakness))
            candidates.append([err, left_start, right_stop])

    candidates.sort()

    print candidates
    winners = []
    for score, left_start, right_stop in candidates:
        if score > THRESHOLD:
            break
        if not any(left_start < e and right_stop > s for s, e, sc in winners):
            winners.append([left_start, right_stop, score])
        else:
            print "rejecting overlapping", left_start, right_stop


    if 1:
        axis = [x * samples2secs for x in range(len(call_diff))]

        plt.plot(axis, call_diff)

        wx = []
        wy = []
        for w in sorted(winners):
            for x in range(int(w[0] / samples2secs), int(w[1] / samples2secs)):
                wx.append(x * samples2secs)
                wy.append(THRESHOLD - w[2])
        plt.plot(wx, wy, '^')
        sx, sy = [], []
        for i, s in enumerate(starts):
            for x in range(*s):
                sx.append(x * samples2secs)
                sy.append(-0.1 * i)
        plt.plot(sx, sy, '.')


        plt.show()



    print winners
    return winners




def locate_calls(audio, title=None):
    overlap = NFFT / 2
    audio.calculate_specgram(nfft=NFFT, noverlap=overlap)
    #find the intensity in the frequencies that  use, using a
    #simple square filter.
    call_band = np.where((audio.specgram_freqs >= LOWER_CALL_FREQUENCY) *
                         (audio.specgram_freqs <= UPPER_CALL_FREQUENCY))[0]

    call_specgram = audio.specgram[call_band]

    call_max = np.max(call_specgram, 0)
    call_min = np.median(call_specgram, 0)

    duration = float(audio.duration)
    #effective_samples = overlap * (len(call_max) - 1.0) + NFFT
    #XXX better conversion is possible
    samples2secs = duration / len(call_max)

    call_bin = call_max / call_min
    smooth_call_bin = smooth(call_bin, radius=5)
    background = smooth(call_bin, radius=150, shape=2)

    call_ratio = smooth_call_bin / background
    call_diff = smooth_call_bin - background
    if USE_CALL_RATIO:
        winners = find_calls_in_call_diff(call_ratio, CALL_RATIO_THRESHOLD_LEFT, CALL_RATIO_THRESHOLD_RIGHT, samples2secs)
    else:
        winners = find_calls_in_call_diff(call_diff, CALL_DIFF_THRESHOLD_LEFT, CALL_DIFF_THRESHOLD_RIGHT, samples2secs)

    #print winners
    return sorted(x[:2] for x in winners)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('-o',
        '--output',
        default=sys.stdout,
        type=argparse.FileType('w'),
        help='output file')
    parser.add_argument('paths', nargs='+', help='paths to walk over', default=['.'])
    args = parser.parse_args()

    for path in args.paths:
        for root, dirs, files in os.walk(path):
            for f in sorted(files):
                if f.endswith(".wav"):
                    path = os.path.join(root, f)
                    audio = get_audio(path)
                    print path,
                    sys.stderr.flush()
                    print ' '.join('%.2f-%.2f' % (x, y)
                                   for x, y in locate_calls(audio, f))

main()
